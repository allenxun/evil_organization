\relax 
\bibstyle{plain}
\@writefile{toc}{\contentsline {section}{\numberline {1}Adversarial Machine Learning (AML, 对抗机器学习）}{2}\protected@file@percent }
\newlabel{sec:diyijie}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}攻击：如何生成对抗样本}{3}\protected@file@percent }
\newlabel{sec:dierjie}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}白盒攻击（White-Box Adversarial）}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}黑盒攻击（Black-Box Adversarial）}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}防御：如何让机器学习模型更鲁棒}{4}\protected@file@percent }
\newlabel{sec:disanjie}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}另一个博客的分类}{5}\protected@file@percent }
\newlabel{sec:disijie}{{4}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}CCS 2017-AIsec-Adversarial Machine Learning 方向三篇论文摘要}{6}\protected@file@percent }
\newlabel{sec:diwujie}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Making Targeted Black-box Evasion Attacks Effective and Efficient(Mika Juuti, Buse Gul Atli, N. Asokan)}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Interpolated Adversarial Training: Achieving Robust Neural Networks Without Sacrificing Too Much Accuracy}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Analyzing the Robustness of Open-World Machine Learning}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}相关知识}{7}\protected@file@percent }
\newlabel{sec:diliujie}{{6}{7}}
\bibdata{test}
